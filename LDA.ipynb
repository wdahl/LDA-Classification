{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of Xp:\n",
      "[[4.   ]\n",
      " [3.125]\n",
      " [0.25 ]] \n",
      "\n",
      "mean of Xn:\n",
      "[[8.4]\n",
      " [7.6]\n",
      " [0.2]] \n",
      "\n",
      "Covarince matrix of Xp:\n",
      "[[30.    -6.    -5.   ]\n",
      " [-6.    16.875 -1.25 ]\n",
      " [-5.    -1.25   3.5  ]] \n",
      "\n",
      "Covarince matrix of Xn:\n",
      "[[ 9.2 -0.2 -1.4]\n",
      " [-0.2 13.2  1.4]\n",
      " [-1.4  1.4  2.8]] \n",
      "\n",
      "Scartter within matrix:\n",
      "[[39.2   -6.2   -6.4  ]\n",
      " [-6.2   30.075  0.15 ]\n",
      " [-6.4    0.15   6.3  ]] \n",
      "\n",
      "Scatter between matrix:\n",
      "[[ 1.9360000e+01  1.9690000e+01 -2.2000000e-01]\n",
      " [ 1.9690000e+01  2.0025625e+01 -2.2375000e-01]\n",
      " [-2.2000000e-01 -2.2375000e-01  2.5000000e-03]] \n",
      "\n",
      "Optimal LDA projection Direction vector:\n",
      "[[0.56941154]\n",
      " [0.62283144]\n",
      " [0.53651793]] \n",
      "\n",
      "classes for each cloumn of data in X\n",
      "[1, -1, 1, 1, 1, -1]\n"
     ]
    }
   ],
   "source": [
    "#William Dahl\n",
    "#ICSI 436\n",
    "#HW 4\n",
    "#March 12th, 2019\n",
    "import numpy as np\n",
    "\n",
    "#positive matrix\n",
    "Xp = np.matrix([[4,2,2,3,4,6,3,8],\n",
    "                [1,4,3,6,4,2,2,3],\n",
    "                [0,1,1,0,-1,0,1,0]])\n",
    "\n",
    "#negative matrix\n",
    "Xn = np.matrix([[9,6,9,8,10],\n",
    "                [10,8,5,7,8],\n",
    "                [1,0,0,1,-1]])\n",
    "\n",
    "#calculates the mean of a martix\n",
    "def mean(X):\n",
    "    return np.mean(X, axis=1)\n",
    "\n",
    "#calculates the covarince matrix of a given matrix\n",
    "def cov(X, m):\n",
    "    return (X-m) * (X-m).getT()\n",
    "\n",
    "#calcultes the scatter within matrix\n",
    "def scatter_within(Cp, Cn):\n",
    "    return Cp + Cn\n",
    "\n",
    "#calculates the scatter between martix\n",
    "def scatter_between(Mp, Mn):\n",
    "    return (Mp - Mn) * (Mp - Mn).T\n",
    "\n",
    "#gets the optimal projection vector\n",
    "def LDA(Sw, Sb):\n",
    "    #gest the eigen values and the egin vectors of Sw.ISb\n",
    "    eig_vals, eig_vecs = np.linalg.eig(Sw.getI() * Sb)\n",
    "\n",
    "    #sorts the eigen values from higest to lowest and the respectinve eigen vector\n",
    "    eig_pairs = [(eig_vals[i], eig_vecs[:,i]) for i in range(len(eig_vals))]\n",
    "    eig_pairs = sorted(eig_pairs, key=lambda k: k[0], reverse=True)\n",
    "    \n",
    "    #returns the eigeinvector ascoaiated with the highest eign value\n",
    "    return eig_pairs[0][1]\n",
    "    \n",
    "\n",
    "Mp = mean(Xp)\n",
    "print('mean of Xp:')\n",
    "print(Mp, '\\n')\n",
    "\n",
    "Mn = mean(Xn)\n",
    "print('mean of Xn:')\n",
    "print(Mn, '\\n')\n",
    "\n",
    "Cp = cov(Xp, Mp)\n",
    "print('Covarince matrix of Xp:')\n",
    "print(Cp, '\\n')\n",
    "\n",
    "Cn = cov(Xn, Mn)\n",
    "print('Covarince matrix of Xn:')\n",
    "print(Cn, '\\n')\n",
    "\n",
    "Sw = scatter_within(Cp, Cn)\n",
    "print('Scartter within matrix:')\n",
    "print(Sw, '\\n')\n",
    "\n",
    "Sb = scatter_between(Mp, Mn)\n",
    "print('Scatter between matrix:')\n",
    "print(Sb, '\\n')\n",
    "\n",
    "v = LDA(Sw, Sb)\n",
    "print('Optimal LDA projection Direction vector:')\n",
    "print(v, '\\n')\n",
    "\n",
    "#gets the optimal projection vector for the classes\n",
    "def mybLDA_train(Xp, Xn):\n",
    "    Mp = mean(Xp)\n",
    "    Mn = mean(Xn)\n",
    "    Cp = cov(Xp, Mp)\n",
    "    Cn = cov(Xn, Mn)\n",
    "    Sw = scatter_within(Cp, Cn)\n",
    "    Sb = scatter_between(Mp, Mn)\n",
    "    return LDA(Sw, Sb)\n",
    "\n",
    "#classifys new data using the projection vector\n",
    "def mynLDA_classify(X, v):\n",
    "    #holds the classes for each new data object in the data matrix\n",
    "    r = list()\n",
    "    for i in range(X.shape[1]):\n",
    "        #calculates the 1D representation for the new data object along the projection vector\n",
    "        y = v.T * X[:,i]\n",
    "        #uses 7 as a threshold for classes\n",
    "        if y <= 7:\n",
    "            #if value is less than 7 the class is positive\n",
    "            r.append(1)\n",
    "        else:\n",
    "            #if value is greater than 7 the class is negative\n",
    "            r.append(-1)\n",
    "            \n",
    "    return r\n",
    "\n",
    "#new data to be classified\n",
    "X = np.matrix([[1.3, 2.4, 6.7, 2.2, 3.4, 3.2],\n",
    "               [8.1, 7.6, 2.1, 1.1, 0.5, 7.4],\n",
    "               [ -1,   2,   3,  -2,   0,   2]])\n",
    "\n",
    "v = (mybLDA_train(Xp, Xn))\n",
    "\n",
    "print(\"classes for each cloumn of data in X\")\n",
    "print(mynLDA_classify(X,v))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
